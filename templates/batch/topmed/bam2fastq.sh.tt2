#!/bin/sh
[% IF settings.cluster == 'csg' -%]
#SBATCH --nodes=1
#SBATCH --cpus-per-task=[% job.procs %]
#SBATCH --mem=[% job.memory %]
#SBATCH --gres=tmp:100
#SBATCH --time=[% job.walltime %]
#SBATCH --workdir=[% job.workdir %]
#SBATCH --partition=topmed
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=[% job.email %]
#SBATCH --job-name=[% job.job_name %]
#SBATCH --nodes=1-1

JOB_ID=$SLURM_JOB_ID
NODELIST=$SLURM_JOB_NODELIST
[% ELSIF settings.cluster == 'flux' -%]
#PBS -l nodes=1:ppn=[% job.procs %]
#PBS -l walltime=[% job.walltime %]
#PBS -l pmem=[% job.memory %]gb
#PBS -l ddisk=100gb
#PBS -m a
#PBS -d [% job.workdir %]
#PBS -M [% job.email %]
#PBS -q flux
#PBS -l qos=flux
#PBS -A [% job.account %]
#PBS -V
#PBS -j oe
#PBS -N [% job.job_name %]

JOB_ID=$PBS_JOBID
NODELIST=$(cat $PBS_NODEFILE)
[% END -%]

set -eu -o pipefail

export PERL_CARTON_PATH=[% settings.project_dir %]/local
export PERL5LIB=${PERL_CARTON_PATH}/lib/perl5:[% settings.project_dir %]/lib/perl5:${PERL5LIB}
export PATH=[% settings.project_dir %]/bin:${PERL_CARTON_PATH}/bin:${PATH}

META_ID=[% settings.meta_id %]
MAPPER_CMD=[% settings.mapper_cmd %]
MAPPER_LOG_CMD="$MAPPER_CMD log --meta-id $META_ID"
MAPPER_UPDATE_CMD="$MAPPER_CMD update --meta-id $META_ID --step bam2fastq"
TMP_DIR=[% settings.tmp_dir %]

$MAPPER_UPDATE_CMD --start --job-id $JOB_ID --node $NODELIST
$MAPPER_LOG_CMD --message 'starting bam2fastq'

JOB_TMP_BASE=/tmp/[% settings.project %]
[% IF settings.cluster == 'csg' -%]
if [ -d $JOB_TMP_BASE ]; then
  for id in $(ls -1 $JOB_TMP_BASE); do
    if [ $id == 'hg38' ]; then
      continue
    fi

    job_state="$(sacct -j $id -X -n -o state%7)"
    if [ "$job_state" != "RUNNING " ]; then # XXX - left trailing space on purpose
      tmp_dir=${JOB_TMP_BASE}/${id}
      $MAPPER_LOG_CMD --message "removing stale job tmp directory $tmp_dir"
      rm -rf $tmp_dir
    fi
  done
fi
[% ELSIF settings.cluster == 'flux' -%]
if [ -d $JOB_TMP_BASE ]; then
  for id in $(ls -1 $JOB_TMP_BASE); do
    if [ $id == 'hg38' ]; then
      continue
    fi

    qstat -f -e $id > /dev/null 2>&1
    if [ $? -ne 0 ]; then
      tmp_dir=${JOB_TMP_BASE}/${id}
      $MAPPER_LOG_CMD --message "removing stale job tmp directory $tmp_dir"
      rm -rf $tmp_dir
    fi
  done
fi
[% END -%]

JOB_TMP_DIR=${JOB_TMP_BASE}/${JOB_ID}
$MAPPER_LOG_CMD --message "creating JOB_TMP_DIR $JOB_TMP_DIR"
mkdir -p $JOB_TMP_DIR

if [ $? -ne 0 ]; then
  $MAPPER_LOG_CMD --message "failed to create JOB_TMP_DIR $JOB_TMP_DIR" --level critical
  $MAPPER_UPDATE_CMD --state failed
  exit 1
elif [ ! -d $JOB_TMP_DIR ]; then
  $MAPPER_LOG_CMD --message "mkdir returned success but did not create JOB_TMP_DIR $JOB_TMP_DIR" --level critical
  $MAPPER_UPDATE_CMD --state failed
  exit 1
fi

if [ -e $TMP_DIR ]; then
  $MAPPER_LOG_CMD --message "removing existing TMP_DIR $TMP_DIR"
  rm -rf $TMP_DIR
fi

$MAPPER_LOG_CMD --message "creating TMP_DIR $TMP_DIR"
mkdir -p $TMP_DIR

if [ $? -ne 0 ]; then
  $MAPPER_LOG_CMD --message "failed to create TMP_DIR $TMP_DIR" --level critical
  $MAPPER_UPDATE_CMD --state failed
  exit 1
elif [ ! -d $TMP_DIR ]; then
  $MAPPER_LOG_CMD --message "mkdir returned success but did not create TMP_DIR $TMP_DIR" --level critical
  $MAPPER_UPDATE_CMD --state failed
  exit 1
fi

$MAPPER_LOG_CMD --message "setting permissions on TMP_DIR $TMP_DIR"
chmod 750 $TMP_DIR

if [ $? -ne 0 ]; then
  $MAPPER_LOG_CMD --message "failed to set permissions on TMP_DIR $TMP_DIR" --level critical
  $MAPPER_UPDATE_CMD --state failed
  exit 1
fi

$MAPPER_LOG_CMD --message "delaying execution for [% settings.delay %] minutes"
sleep "[% settings.delay %]m"

$MAPPER_CMD show --job-info $META_ID > [% settings.job_log %].$JOB_ID
$MAPPER_CMD show --sample-info [% sample.sample_id %] >> [% settings.job_log %].$JOB_ID

$MAPPER_LOG_CMD --message 'generating flagstat for src cram [% sample.incoming_path %]'
flagstat_file=[% job.workdir %]/[% sample.sample_id %].src.flagstat
[% gotcloud.samtools %] flagstat [% sample.incoming_path %] > $flagstat_file
if [ $? -ne 0 ]; then
  $MAPPER_LOG_CMD --message 'failed to generate flagstat for sample [% sample.incoming_path %]' --level critical
  exit 1
fi

rc=0
$MAPPER_LOG_CMD --message 'beginning bam2fastq pipeline'
export REF_CACHE=[% gotcloud.ref_dir %]/../hg38/md5/%2s/%2s/%s
[% IF sample.center == 'illumina' && sample.ref_build == '37' -%]
[% gotcloud.samtools %] view -uh -F 0x900 -T [% gotcloud.illumina_ref %] [% sample.incoming_path %] \
[% ELSE -%]
[% gotcloud.samtools %] view -uh -F 0x900 [% sample.incoming_path %] \
[% END -%]
  | [% gotcloud.bam_util %] squeeze --in -.ubam --keepDups --rmTags AS:i,BD:Z,BI:Z,XS:i,MC:Z,MD:Z,NM:i,MQ:i --out -.ubam \
  | [% gotcloud.samtools %] sort -l 1 -@ [% job.procs %] -m 4000M -n -T $JOB_TMP_DIR - \
  | [% gotcloud.samtools %] fixmate - - \
  | [% gotcloud.bam_util %] bam2fastq --in -.bam --outBase ${TMP_DIR}/[% sample.sample_id %] --maxRecordLimitPerFq 20000000 --sortByReadNameOnTheFly --readname --gzip 2> ${TMP_DIR}/fastq.log

rc=$?
$MAPPER_LOG_CMD --message "pipe_rc: $rc"

if [ $rc -eq 0 ]; then
  fastq_list="${TMP_DIR}/[% sample.sample_id %].list"

  $MAPPER_LOG_CMD --message "processing fastq list $fastq_list"
  $MAPPER_UPDATE_CMD --fastq-list $fastq_list

  if [ $? -eq 0 ]; then
    $MAPPER_LOG_CMD --message 'validating bam2fastq pipeline results'

    fastq_reads=0
    for fastq in $(awk {'print $2'} $fastq_list | grep -v FASTQ1); do
      reads=$(( $(zcat $fastq | wc -l) / 4 ))
      fastq_reads=$(( $fastq_reads + $reads ))

      $MAPPER_UPDATE_CMD --fastq $fastq --reads $reads
    done

    cram_reads=$(grep 'paired in sequencing' $flagstat_file | awk {'print $1'})
    if [ $fastq_reads -eq $cram_reads ]; then
      $MAPPER_LOG_CMD --message "reads matched for source cram[$cram_reads] and generated fastqs[$fastq_reads]"
    else
      $MAPPER_LOG_CMD --message "reads did not match for source cram[$cram_reads] and generated fastqs[$fastq_reads]" --level critical
      rc=1
    fi
  else
    $MAPPER_LOG_CMD --message "failed to process the fastq list file" --level critical
    rc=1
  fi
fi

$MAPPER_LOG_CMD --message 'beginning upload to google cloud storage'
gsutil -m -o GSUtil:parallel_composite_upload_threshold=150M rsync -r $TMP_DIR [% google.fastq_bucket %]/[% sample.sample_id %]
if [ $? -eq 0 ]; then
  $MAPPER_LOG_CMD --message 'completed upload to google cloud storage'
  # TODO - cleanup $TMP_DIR, or maybe not, no local copy means no flux processing
else
  $MAPPER_LOG_CMD --message 'failed to upload to google cloud storage' --level critical
  rc=1
fi

if [ $rc -eq 0 ]; then
  $MAPPER_LOG_CMD --message "deleteing job tmp directory $JOB_TMP_DIR"
  rm -rf $JOB_TMP_DIR

  $MAPPER_LOG_CMD --message "[% settings.pipeline %] completed with exit code $rc"
  $MAPPER_UPDATE_CMD --state completed --exit-code $rc
else
  $MAPPER_LOG_CMD --message "[% settings.pipeline %] failed with exit code $rc" --level critical
  $MAPPER_UPDATE_CMD --state failed --exit-code $rc
fi

exit $rc
